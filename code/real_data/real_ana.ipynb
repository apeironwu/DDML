{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "436f21ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from timeit import default_timer as timer\n",
    "import time\n",
    "import sys, getopt\n",
    "import math\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc851166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/lustre/project/Stat/s1155168529/programs/DDML/code/real_data'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/lustre/project/Stat/s1155168529/programs/DDML/code/real_data')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef0963e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 1\n",
    "K = 3  #number of sites \n",
    "K_fold = 3\n",
    "n_rft = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9f236ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_beta_est_iter = np.zeros(n_iter)\n",
    "adni1_pd = pd.read_csv('adni1.csv')\n",
    "adni2_pd = pd.read_csv('adni2.csv')\n",
    "adnigo_pd = pd.read_csv('adnigo.csv')\n",
    "adni1= adni1_pd.values\n",
    "adni2= adni2_pd.values\n",
    "adnigo= adnigo_pd.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74a828a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = [adni1,adni2,adnigo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6efe9942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 240 candidates, totalling 720 fits\n",
      "Best parameters: {'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor()\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [20, 50, 100, 200],\n",
    "    'max_depth': [None, 5, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 5, 10]\n",
    "}\n",
    "\n",
    "# Setup the grid search\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=1)\n",
    "\n",
    "# Fit grid search\n",
    "best_model1_d = grid_search.fit(df[0][:,6:20], df[0][:,22])\n",
    "\n",
    "# Get the best parameters\n",
    "print(\"Best parameters:\", best_model1_d.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d02b727a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Best parameters: {'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [20, 50, 100],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 5, 10]\n",
    "}\n",
    "\n",
    "# Setup the grid search\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=1)\n",
    "\n",
    "# Fit grid search\n",
    "best_model1_y = grid_search.fit(df[0][:,6:20], df[0][:,21])\n",
    "\n",
    "# Get the best parameters\n",
    "print(\"Best parameters:\", best_model1_y.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0049761a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Best parameters: {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [20, 50, 100],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 5, 10]\n",
    "}\n",
    "\n",
    "# Setup the grid search\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=1)\n",
    "\n",
    "# Fit grid search\n",
    "best_model2_d = grid_search.fit(df[1][:,6:20], df[1][:,22])\n",
    "\n",
    "# Get the best parameters\n",
    "print(\"Best parameters:\", best_model2_d.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d8a365b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Best parameters: {'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 20}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [20, 50, 100],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 5, 10]\n",
    "}\n",
    "\n",
    "# Setup the grid search\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=1)\n",
    "\n",
    "# Fit grid search\n",
    "best_model2_y = grid_search.fit(df[1][:,6:20], df[1][:,21])\n",
    "\n",
    "# Get the best parameters\n",
    "print(\"Best parameters:\", best_model2_y.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36a7258c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Best parameters: {'max_depth': None, 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 20}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [20, 50, 100],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 5, 10]\n",
    "}\n",
    "\n",
    "# Setup the grid search\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=1)\n",
    "\n",
    "# Fit grid search\n",
    "best_model3_d = grid_search.fit(df[2][:,6:20], df[2][:,22])\n",
    "\n",
    "# Get the best parameters\n",
    "print(\"Best parameters:\", best_model3_d.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a10f4dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Best parameters: {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [20, 50, 100],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 5, 10]\n",
    "}\n",
    "\n",
    "# Setup the grid search\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=1)\n",
    "\n",
    "# Fit grid search\n",
    "best_model3_y = grid_search.fit(df[2][:,6:20], df[2][:,21])\n",
    "\n",
    "# Get the best parameters\n",
    "print(\"Best parameters:\", best_model3_y.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "769103da",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_d = [best_model1_d.best_params_,best_model2_d.best_params_,best_model3_d.best_params_]\n",
    "param_y = [best_model1_y.best_params_,best_model2_y.best_params_,best_model3_y.best_params_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ae88d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = len(adni1)\n",
    "n2 = len(adni2)\n",
    "n3 = len(adnigo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4de67f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.45392491, 0.46211604, 0.08395904])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_weight = [n1, n2, n3]\n",
    "vec_weight = vec_weight / np.sum(vec_weight)\n",
    "vec_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "408293d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating empty arrays with 0 rows but defined number of columns\n",
    "array1 = [0]*n1\n",
    "array2 = [0]*n2\n",
    "array3 = [0]*n3\n",
    "\n",
    "# Creating a list to contain these arrays\n",
    "idx_K_fold = [array1, array2, array3]\n",
    "idx_K_fold[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad927d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "idx_K_fold[0] = np.random.choice(range(K_fold), n1, replace=True)\n",
    "\n",
    "np.random.seed(1)\n",
    "idx_K_fold[1] = np.random.choice(range(K_fold), n2, replace=True)\n",
    "\n",
    "np.random.seed(1)\n",
    "idx_K_fold[2] = np.random.choice(range(K_fold), n3, replace=True)\n",
    "\n",
    "i_iter = 0\n",
    "list_gamma_est = list()\n",
    "list_mu_est = list()\n",
    "mat_beta_est_local = np.zeros((K, K_fold))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a5fd54",
   "metadata": {},
   "source": [
    "## DDML initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1efa8a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(K):\n",
    "    for splt in range(K_fold):\n",
    "        idx_est = np.where(idx_K_fold[j] == splt)[0]\n",
    "        idx_nui = np.where(idx_K_fold[j] != splt)[0]\n",
    "        n_est = idx_est.shape[0]\n",
    "        ## training ML model\n",
    "        mat_X_nui = df[j][idx_nui, 6:20]\n",
    "        vec_D_nui = df[j][idx_nui, 22]\n",
    "        vec_Y_nui = df[j][idx_nui, 21]\n",
    "                        \n",
    "        ## estimating\n",
    "        mat_X_est = df[j][idx_est, 6:20]\n",
    "        vec_D_est = df[j][idx_est, 22]\n",
    "        vec_Y_est = df[j][idx_est, 21]\n",
    "        \n",
    "        # model_mu = RandomForestRegressor(n_estimators=n_rft)\n",
    "        model_mu = RandomForestRegressor(**param_d[j])\n",
    "        model_mu.fit(mat_X_nui, vec_D_nui)\n",
    "                        \n",
    "        ## estimation of beta based on partialling out score function\n",
    "        # model_xi = RandomForestRegressor(n_estimators=n_rft)\n",
    "        model_xi = RandomForestRegressor(**param_y[j])\n",
    "        model_xi.fit(mat_X_nui, vec_Y_nui)\n",
    "                        \n",
    "        vec_D_diff = vec_D_est - model_mu.predict(mat_X_est)\n",
    "        vec_Y_diff = vec_Y_est - model_xi.predict(mat_X_est)\n",
    "                        \n",
    "        beta_est_local = np.mean(vec_Y_diff * vec_D_diff) / np.mean(vec_D_diff * vec_D_diff)\n",
    "\n",
    "        model_gamma = RandomForestRegressor(n_estimators=50)\n",
    "        model_gamma.fit(mat_X_nui, vec_Y_nui - vec_D_nui * beta_est_local)\n",
    "\n",
    "        list_mu_est.append(model_mu)\n",
    "        list_gamma_est.append(model_gamma)\n",
    "\n",
    "        mat_beta_est_local[j, splt] = beta_est_local\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aeca1091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.47895907, 0.50797948, 0.38176787],\n",
       "       [0.38112781, 0.45362422, 0.36306013],\n",
       "       [0.15473572, 0.04598916, 0.15727577]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_beta_est_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98bda2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mat_beta_est_local:  [0.45623548 0.39927072 0.11933355]\n",
      "beta_est_int (weighted):  0.40162518491909943\n",
      "beta_est_ini (unweighted):  0.3249465826347872\n"
     ]
    }
   ],
   "source": [
    "print(\"mat_beta_est_local: \", mat_beta_est_local.mean(1))\n",
    "print(\"beta_est_int (weighted): \", np.sum(mat_beta_est_local.mean(1) * vec_weight))\n",
    "print(\"beta_est_ini (unweighted): \", mat_beta_est_local.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5eb09a8",
   "metadata": {},
   "source": [
    "## (Weighted) DDML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e4141573",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DDML\n",
    "beta_est_ini = np.sum(mat_beta_est_local.mean(1) * vec_weight)\n",
    "\n",
    "mat_beta_est_cen = np.zeros((K, K_fold))\n",
    "\n",
    "for splt in range(K_fold): \n",
    "    for j in range(K):\n",
    "        idx_est = np.where(idx_K_fold[j] == splt)[0]\n",
    "\n",
    "        n_est = idx_est.shape[0]\n",
    "\n",
    "        ## statistics from other sites\n",
    "        vec_s = np.zeros(n_est)\n",
    "        vec_S_est = np.zeros(K)\n",
    "        idx_ls = j + splt * K\n",
    "\n",
    "        ## estimating\n",
    "        mat_X_est = df[j][idx_est, 6:20]\n",
    "        vec_D_est = df[j][idx_est, 22]\n",
    "        vec_Y_est = df[j][idx_est, 21]\n",
    "\n",
    "        vec_D_diff = vec_D_est - list_mu_est[idx_ls].predict(mat_X_est)\n",
    "        vec_Y_diff = vec_Y_est - list_gamma_est[idx_ls].predict(mat_X_est)\n",
    "                        \n",
    "        vec_s = (vec_Y_diff - vec_D_est * beta_est_ini) * vec_D_diff\n",
    "                        \n",
    "        vec_S_est[j] = np.mean(vec_s)\n",
    "    \n",
    "    S = np.sum(vec_S_est * vec_weight)\n",
    "    # S = np.mean(vec_S_est)\n",
    "    \n",
    "    for j_cen in range(K):\n",
    "        idx_est = np.where(idx_K_fold[j] == splt)[0]\n",
    "\n",
    "        n_est = idx_est.shape[0]\n",
    "        \n",
    "        idx_ls_cen = j_cen + splt * K\n",
    "\n",
    "        vec_Y_cen = df[j_cen][idx_est, 21]\n",
    "        vec_D_cen = df[j_cen][idx_est, 22]\n",
    "        mat_X_cen = df[j_cen][idx_est,6:20]\n",
    "\n",
    "        mat_U_slope = np.zeros((n_est, K))\n",
    "\n",
    "        # single-equation density estimation\n",
    "        vec_Y_cen_diff = vec_Y_cen - list_gamma_est[idx_ls_cen].predict(mat_X_cen)\n",
    "\n",
    "        vec_U_cen_est = vec_Y_cen_diff - vec_D_cen * beta_est_ini\n",
    "        for j in range(K):\n",
    "            idx_ls = j + splt * K\n",
    "\n",
    "            vec_D_loc_diff = vec_D_cen - list_mu_est[idx_ls].predict(mat_X_cen)\n",
    "\n",
    "            vec_Y_loc_diff = vec_Y_cen - list_gamma_est[idx_ls].predict(mat_X_cen)\n",
    "                            \n",
    "            vec_U_loc_est = vec_Y_loc_diff - vec_D_cen * beta_est_ini\n",
    "                            \n",
    "            ## density ratio\n",
    "            varU_loc = np.mean(np.power(vec_U_loc_est, 2))\n",
    "            varU_cen = np.mean(np.power(vec_U_cen_est, 2))\n",
    "            mat_U_slope[:, j] = np.power(vec_U_loc_est, 2)/(2*varU_loc) - np.power(vec_U_cen_est, 2)/(2*varU_cen)\n",
    "            mat_U_slope[:, j] = np.exp(-1* mat_U_slope[:, j])\n",
    "            mat_U_slope[:, j] = mat_U_slope[:, j] * math.sqrt(varU_cen)/math.sqrt(varU_loc)\n",
    "            mat_U_slope[:, j] = mat_U_slope[:, j] * vec_D_cen * vec_D_loc_diff\n",
    "            mat_U_slope[:, j] = mat_U_slope[:, j] * vec_weight[j]\n",
    "        U_slope = np.mean(mat_U_slope.sum(1))\n",
    "        \n",
    "        beta_est_cen = beta_est_ini + S / U_slope\n",
    "        mat_beta_est_cen[j_cen, splt] = beta_est_cen\n",
    "\n",
    "\n",
    "## final estimation\n",
    "beta_est = np.mean(mat_beta_est_cen)\n",
    "    \n",
    "vec_beta_est_iter[i_iter] = beta_est\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a964f3ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.40237294, 0.38498917, 0.39197847],\n",
       "       [0.40338493, 0.3709791 , 0.39120924],\n",
       "       [0.40289637, 0.38517547, 0.39121   ]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_beta_est_cen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d3d38b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Weighted) mat_beta_est_cen:  [0.40288454 0.37853053 0.39155848]\n",
      "(Weighted) DDML estimator:  0.39099118322355314\n"
     ]
    }
   ],
   "source": [
    "print(\"(Weighted) mat_beta_est_cen: \", np.matmul(vec_weight.transpose(), mat_beta_est_cen))\n",
    "print(\"(Weighted) DDML estimator: \", np.sum(mat_beta_est_cen.mean(1) * vec_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e8f4e7",
   "metadata": {},
   "source": [
    "## (Unweighted) DDML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1deec4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DDML\n",
    "beta_est_ini = mat_beta_est_local.mean()\n",
    "\n",
    "mat_beta_est_cen = np.zeros((K, K_fold))\n",
    "\n",
    "for splt in range(K_fold): \n",
    "    for j in range(K):\n",
    "        idx_est = np.where(idx_K_fold[j] == splt)[0]\n",
    "\n",
    "        n_est = idx_est.shape[0]\n",
    "\n",
    "        ## statistics from other sites\n",
    "        vec_s = np.zeros(n_est)\n",
    "        vec_S_est = np.zeros(K)\n",
    "        idx_ls = j + splt * K\n",
    "\n",
    "        ## estimating\n",
    "        mat_X_est = df[j][idx_est, 6:20]\n",
    "        vec_D_est = df[j][idx_est, 22]\n",
    "        vec_Y_est = df[j][idx_est, 21]\n",
    "\n",
    "        vec_D_diff = vec_D_est - list_mu_est[idx_ls].predict(mat_X_est)\n",
    "        vec_Y_diff = vec_Y_est - list_gamma_est[idx_ls].predict(mat_X_est)\n",
    "                        \n",
    "        vec_s = (vec_Y_diff - vec_D_est * beta_est_ini) * vec_D_diff\n",
    "                        \n",
    "        vec_S_est[j] = np.mean(vec_s)\n",
    "    \n",
    "    # S = np.sum(vec_S_est * vec_weight)\n",
    "    S = np.mean(vec_S_est)\n",
    "    \n",
    "    for j_cen in range(K):\n",
    "        idx_est = np.where(idx_K_fold[j] == splt)[0]\n",
    "\n",
    "        n_est = idx_est.shape[0]\n",
    "        \n",
    "        idx_ls_cen = j_cen + splt * K\n",
    "\n",
    "        vec_Y_cen = df[j_cen][idx_est, 21]\n",
    "        vec_D_cen = df[j_cen][idx_est, 22]\n",
    "        mat_X_cen = df[j_cen][idx_est,6:20]\n",
    "\n",
    "        mat_U_slope = np.zeros((n_est, K))\n",
    "\n",
    "        # single-equation density estimation\n",
    "        vec_Y_cen_diff = vec_Y_cen - list_gamma_est[idx_ls_cen].predict(mat_X_cen)\n",
    "\n",
    "        vec_U_cen_est = vec_Y_cen_diff - vec_D_cen * beta_est_ini\n",
    "        for j in range(K):\n",
    "            idx_ls = j + splt * K\n",
    "\n",
    "            vec_D_loc_diff = vec_D_cen - list_mu_est[idx_ls].predict(mat_X_cen)\n",
    "\n",
    "            vec_Y_loc_diff = vec_Y_cen - list_gamma_est[idx_ls].predict(mat_X_cen)\n",
    "                            \n",
    "            vec_U_loc_est = vec_Y_loc_diff - vec_D_cen * beta_est_ini\n",
    "                            \n",
    "            ## density ratio\n",
    "            varU_loc = np.mean(np.power(vec_U_loc_est, 2))\n",
    "            varU_cen = np.mean(np.power(vec_U_cen_est, 2))\n",
    "            mat_U_slope[:, j] = np.power(vec_U_loc_est, 2)/(2*varU_loc) - np.power(vec_U_cen_est, 2)/(2*varU_cen)\n",
    "            mat_U_slope[:, j] = np.exp(-1* mat_U_slope[:, j])\n",
    "            mat_U_slope[:, j] = mat_U_slope[:, j] * math.sqrt(varU_cen)/math.sqrt(varU_loc)\n",
    "            mat_U_slope[:, j] = mat_U_slope[:, j] * vec_D_cen * vec_D_loc_diff\n",
    "            # mat_U_slope[:, j] = mat_U_slope[:, j] * vec_weight[j]\n",
    "        U_slope = np.mean(mat_U_slope.sum(1))\n",
    "        \n",
    "        beta_est_cen = beta_est_ini + S / U_slope\n",
    "        mat_beta_est_cen[j_cen, splt] = beta_est_cen\n",
    "\n",
    "\n",
    "## final estimation\n",
    "beta_est = np.mean(mat_beta_est_cen)\n",
    "vec_beta_est_iter[i_iter] = beta_est\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d8a5378b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.32953352, 0.31024512, 0.31764127],\n",
       "       [0.33598084, 0.30024206, 0.31717861],\n",
       "       [0.33364939, 0.30927443, 0.3163754 ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_beta_est_cen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "256deb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Unweighted) mat_beta_est_cen:  [0.33305458 0.3065872  0.31706509]\n",
      "(Unweighted) DDML estimator:  0.3189022923401904\n"
     ]
    }
   ],
   "source": [
    "print(\"(Unweighted) mat_beta_est_cen: \", mat_beta_est_cen.mean(0))\n",
    "print(\"(Unweighted) DDML estimator: \", mat_beta_est_cen.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08ae5f0",
   "metadata": {},
   "source": [
    "## (Weighted) Naive Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "03621dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "K=1\n",
    "mat_beta_est_local = np.zeros((K, K_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7fe88671",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for splt in range(K_fold):\n",
    "    idx_est1 = np.where(idx_K_fold[0] == splt)[0]\n",
    "    idx_nui1 = np.where(idx_K_fold[0] != splt)[0]\n",
    "    n_est1 = idx_est1.shape[0]\n",
    "    idx_est2 = np.where(idx_K_fold[1] == splt)[0]\n",
    "    idx_nui2 = np.where(idx_K_fold[1] != splt)[0]\n",
    "    n_est2 = idx_est2.shape[0]\n",
    "    idx_est3 = np.where(idx_K_fold[2] == splt)[0]\n",
    "    idx_nui3 = np.where(idx_K_fold[2] != splt)[0]\n",
    "    n_est3 = idx_est3.shape[0]\n",
    "    ## training ML model\n",
    "    mat_X_nui1 = df[0][idx_nui1, 6:20]\n",
    "    vec_D_nui1 = df[0][idx_nui1, 22]\n",
    "    vec_Y_nui1 = df[0][idx_nui1, 21]\n",
    "    \n",
    "    mat_X_nui2 = df[1][idx_nui2, 6:20]\n",
    "    vec_D_nui2 = df[1][idx_nui2, 22]\n",
    "    vec_Y_nui2 = df[1][idx_nui2, 21]\n",
    "    \n",
    "    mat_X_nui3 = df[2][idx_nui3, 6:20]\n",
    "    vec_D_nui3 = df[2][idx_nui3, 22]\n",
    "    vec_Y_nui3 = df[2][idx_nui3, 21]\n",
    "                    \n",
    "    ## estimating\n",
    "    mat_X_est1 = df[0][idx_est1, 6:20]\n",
    "    vec_D_est1 = df[0][idx_est1, 22]\n",
    "    vec_Y_est1 = df[0][idx_est1, 21]\n",
    "    \n",
    "    mat_X_est2 = df[1][idx_est2, 6:20]\n",
    "    vec_D_est2 = df[1][idx_est2, 22]\n",
    "    vec_Y_est2 = df[1][idx_est2, 21]\n",
    "    \n",
    "    mat_X_est3 = df[2][idx_est3, 6:20]\n",
    "    vec_D_est3 = df[2][idx_est3, 22]\n",
    "    vec_Y_est3 = df[2][idx_est3, 21]\n",
    "    \n",
    "    \n",
    "    model_mu1 = RandomForestRegressor(**param_d[0])\n",
    "    model_mu1.fit(mat_X_nui1, vec_D_nui1)\n",
    "    \n",
    "    model_mu2 = RandomForestRegressor(**param_d[1])\n",
    "    model_mu2.fit(mat_X_nui2, vec_D_nui2)\n",
    "    \n",
    "    model_mu3 = RandomForestRegressor(**param_d[2])\n",
    "    model_mu3.fit(mat_X_nui3, vec_D_nui3)\n",
    "                    \n",
    "    ## estimation of beta based on partialling out score function\n",
    "    model_xi1 = RandomForestRegressor(**param_y[0])\n",
    "    model_xi1.fit(mat_X_nui1, vec_Y_nui1)\n",
    "    \n",
    "    model_xi2 = RandomForestRegressor(**param_y[1])\n",
    "    model_xi2.fit(mat_X_nui2, vec_Y_nui2)\n",
    "    \n",
    "    model_xi3 = RandomForestRegressor(**param_y[2])\n",
    "    model_xi3.fit(mat_X_nui3, vec_Y_nui3)\n",
    "                    \n",
    "    vec_D_diff1 = vec_D_est1 - model_mu1.predict(mat_X_est1)\n",
    "    vec_Y_diff1 = vec_Y_est1 - model_xi1.predict(mat_X_est1)\n",
    "    \n",
    "    vec_D_diff2 = vec_D_est2 - model_mu2.predict(mat_X_est2)\n",
    "    vec_Y_diff2 = vec_Y_est2 - model_xi2.predict(mat_X_est2)\n",
    "    \n",
    "    vec_D_diff3 = vec_D_est3 - model_mu3.predict(mat_X_est3)\n",
    "    vec_Y_diff3 = vec_Y_est3 - model_xi3.predict(mat_X_est3)\n",
    "    \n",
    "    vec_Y_diff = np.concatenate((vec_Y_diff1,vec_Y_diff2,vec_Y_diff3))\n",
    "    vec_D_diff = np.concatenate((vec_D_diff1,vec_D_diff2,vec_D_diff3))\n",
    "                    \n",
    "    beta_est_local = np.mean(vec_Y_diff * vec_D_diff) / np.mean(vec_D_diff * vec_D_diff)\n",
    "\n",
    "    #model_gamma = RandomForestRegressor(n_estimators=n_rft)\n",
    "    # model_gamma.fit(mat_X_nui, vec_Y_nui - vec_D_nui * beta_est_local)\n",
    "\n",
    "    # list_mu_est.append(model_mu)\n",
    "    # list_gamma_est.append(model_gamma)\n",
    "\n",
    "    mat_beta_est_local[0, splt] = beta_est_local\n",
    "\n",
    "beta_est_ini = np.mean(mat_beta_est_local)\n",
    "\n",
    "#mat_beta_est_cen = np.zeros((K, K_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b52dd960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4167289 , 0.43772722, 0.36471558]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_beta_est_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "25984387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(weighted) naive estimator:  0.422065574022618\n",
      "(unweighted) naive estimator:  0.40639056754459957\n"
     ]
    }
   ],
   "source": [
    "print(\"(weighted) naive estimator: \", np.sum(mat_beta_est_local * vec_weight))\n",
    "print(\"(unweighted) naive estimator: \", np.mean(mat_beta_est_local))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "261d5b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4033606806832741"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_est_ini"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
